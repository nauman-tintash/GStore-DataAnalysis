{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation, Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tintash/anaconda3/envs/TensorflowVirtualEnv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903653, 56)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>date</th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>socialEngagementType</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>device.browser</th>\n",
       "      <th>...</th>\n",
       "      <th>trafficSource.adwordsClickInfo.isVideoAd</th>\n",
       "      <th>trafficSource.adwordsClickInfo.page</th>\n",
       "      <th>trafficSource.adwordsClickInfo.slot</th>\n",
       "      <th>trafficSource.campaign</th>\n",
       "      <th>trafficSource.campaignCode</th>\n",
       "      <th>trafficSource.isTrueDirect</th>\n",
       "      <th>trafficSource.keyword</th>\n",
       "      <th>trafficSource.medium</th>\n",
       "      <th>trafficSource.referralPath</th>\n",
       "      <th>trafficSource.source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>1131660440785968503</td>\n",
       "      <td>1131660440785968503_1472830385</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472830385</td>\n",
       "      <td>1</td>\n",
       "      <td>1472830385</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not provided)</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>377306020877927890</td>\n",
       "      <td>377306020877927890_1472880147</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472880147</td>\n",
       "      <td>1</td>\n",
       "      <td>1472880147</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not provided)</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>3895546263509774583</td>\n",
       "      <td>3895546263509774583_1472865386</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472865386</td>\n",
       "      <td>1</td>\n",
       "      <td>1472865386</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not provided)</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>4763447161404445595</td>\n",
       "      <td>4763447161404445595_1472881213</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472881213</td>\n",
       "      <td>1</td>\n",
       "      <td>1472881213</td>\n",
       "      <td>UC Browser</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google + online</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>27294437909732085</td>\n",
       "      <td>27294437909732085_1472822600</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472822600</td>\n",
       "      <td>2</td>\n",
       "      <td>1472822600</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(not provided)</td>\n",
       "      <td>organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 channelGrouping      date        fullVisitorId  \\\n",
       "0           0  Organic Search  20160902  1131660440785968503   \n",
       "1           1  Organic Search  20160902   377306020877927890   \n",
       "2           2  Organic Search  20160902  3895546263509774583   \n",
       "3           3  Organic Search  20160902  4763447161404445595   \n",
       "4           4  Organic Search  20160902    27294437909732085   \n",
       "\n",
       "                        sessionId  socialEngagementType     visitId  \\\n",
       "0  1131660440785968503_1472830385  Not Socially Engaged  1472830385   \n",
       "1   377306020877927890_1472880147  Not Socially Engaged  1472880147   \n",
       "2  3895546263509774583_1472865386  Not Socially Engaged  1472865386   \n",
       "3  4763447161404445595_1472881213  Not Socially Engaged  1472881213   \n",
       "4    27294437909732085_1472822600  Not Socially Engaged  1472822600   \n",
       "\n",
       "   visitNumber  visitStartTime device.browser         ...           \\\n",
       "0            1      1472830385         Chrome         ...            \n",
       "1            1      1472880147        Firefox         ...            \n",
       "2            1      1472865386         Chrome         ...            \n",
       "3            1      1472881213     UC Browser         ...            \n",
       "4            2      1472822600         Chrome         ...            \n",
       "\n",
       "  trafficSource.adwordsClickInfo.isVideoAd  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "\n",
       "  trafficSource.adwordsClickInfo.page trafficSource.adwordsClickInfo.slot  \\\n",
       "0                                 NaN                                 NaN   \n",
       "1                                 NaN                                 NaN   \n",
       "2                                 NaN                                 NaN   \n",
       "3                                 NaN                                 NaN   \n",
       "4                                 NaN                                 NaN   \n",
       "\n",
       "  trafficSource.campaign  trafficSource.campaignCode  \\\n",
       "0              (not set)                         NaN   \n",
       "1              (not set)                         NaN   \n",
       "2              (not set)                         NaN   \n",
       "3              (not set)                         NaN   \n",
       "4              (not set)                         NaN   \n",
       "\n",
       "  trafficSource.isTrueDirect trafficSource.keyword trafficSource.medium  \\\n",
       "0                        NaN        (not provided)              organic   \n",
       "1                        NaN        (not provided)              organic   \n",
       "2                        NaN        (not provided)              organic   \n",
       "3                        NaN       google + online              organic   \n",
       "4                       True        (not provided)              organic   \n",
       "\n",
       "  trafficSource.referralPath trafficSource.source  \n",
       "0                        NaN               google  \n",
       "1                        NaN               google  \n",
       "2                        NaN               google  \n",
       "3                        NaN               google  \n",
       "4                        NaN               google  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train_modified.csv') # Important!!\n",
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0' 'channelGrouping' 'date' 'fullVisitorId' 'sessionId'\n",
      " 'socialEngagementType' 'visitId' 'visitNumber' 'visitStartTime'\n",
      " 'device.browser' 'device.browserSize' 'device.browserVersion'\n",
      " 'device.deviceCategory' 'device.flashVersion' 'device.isMobile'\n",
      " 'device.language' 'device.mobileDeviceBranding' 'device.mobileDeviceInfo'\n",
      " 'device.mobileDeviceMarketingName' 'device.mobileDeviceModel'\n",
      " 'device.mobileInputSelector' 'device.operatingSystem'\n",
      " 'device.operatingSystemVersion' 'device.screenColors'\n",
      " 'device.screenResolution' 'geoNetwork.city' 'geoNetwork.cityId'\n",
      " 'geoNetwork.continent' 'geoNetwork.country' 'geoNetwork.latitude'\n",
      " 'geoNetwork.longitude' 'geoNetwork.metro' 'geoNetwork.networkDomain'\n",
      " 'geoNetwork.networkLocation' 'geoNetwork.region'\n",
      " 'geoNetwork.subContinent' 'totals.bounces' 'totals.hits'\n",
      " 'totals.newVisits' 'totals.pageviews' 'totals.transactionRevenue'\n",
      " 'totals.visits' 'trafficSource.adContent'\n",
      " 'trafficSource.adwordsClickInfo.adNetworkType'\n",
      " 'trafficSource.adwordsClickInfo.criteriaParameters'\n",
      " 'trafficSource.adwordsClickInfo.gclId'\n",
      " 'trafficSource.adwordsClickInfo.isVideoAd'\n",
      " 'trafficSource.adwordsClickInfo.page'\n",
      " 'trafficSource.adwordsClickInfo.slot' 'trafficSource.campaign'\n",
      " 'trafficSource.campaignCode' 'trafficSource.isTrueDirect'\n",
      " 'trafficSource.keyword' 'trafficSource.medium'\n",
      " 'trafficSource.referralPath' 'trafficSource.source']\n"
     ]
    }
   ],
   "source": [
    "#Print all the column names\n",
    "print(train_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantAttributes = ['visitNumber',\n",
    "#                       'device.deviceCategory',\n",
    "#                       'device.operatingSystem', 'device.browser',\n",
    "                       'geoNetwork.continent', 'geoNetwork.country',\n",
    "                      'totals.hits', 'totals.pageviews', \n",
    "                      'totals.transactionRevenue']\n",
    "#                        'fullVisitorId']\n",
    "#                       'year', 'month', 'weekday',\n",
    "#                       'mean_hits_per_day', 'mean_pageviews_per_day', 'sum_hits_per_day', 'sum_pageviews_per_day']\n",
    "\n",
    "train_data = train_data[relevantAttributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Figure out labeling for country param\n",
    "sortedContinent = train_data.groupby('geoNetwork.continent')['totals.transactionRevenue'].mean()\n",
    "sortedContinent = sortedContinent.sort_values(ascending=False)\n",
    "continentCodeDict = {}\n",
    "i = 0\n",
    "for continent in sortedContinent.index:\n",
    "    continentCodeDict[continent] = i\n",
    "    i += 1\n",
    "    \n",
    "# # sortedSubContinent = train_data.groupby('geoNetwork.subContinent')['totals.transactionRevenue'].mean()\n",
    "# # sortedSubContinent = sortedSubContinent.sort_values(ascending=False)\n",
    "# # SubcontinentCodeDict = {}\n",
    "# # i = 0\n",
    "# # for subcontinent in sortedSubContinent.index:\n",
    "# #     SubcontinentCodeDict[subcontinent] = i\n",
    "# #     i += 1\n",
    "    \n",
    "sortedCountries = train_data.groupby('geoNetwork.country')['totals.transactionRevenue'].mean()\n",
    "sortedCountries = sortedCountries.sort_values(ascending=False)\n",
    "countryCodeDict = {}\n",
    "i = 0\n",
    "for country in sortedCountries.index:\n",
    "    countryCodeDict[country] = i\n",
    "    i += 1\n",
    "    \n",
    "# # sortedCities = train_data.groupby('geoNetwork.city')['totals.transactionRevenue'].mean()\n",
    "# # sortedCities = sortedCities.sort_values(ascending=False)\n",
    "# # cityCodeDict = {}\n",
    "# # i = 0\n",
    "# # for city in sortedCities.index:\n",
    "# #     cityCodeDict[city] = i\n",
    "# #     i += 1\n",
    "    \n",
    "# sortedDevices = train_data.groupby('device.operatingSystem')['totals.transactionRevenue'].mean()\n",
    "# sortedDevices = sortedDevices.sort_values(ascending=False)\n",
    "# deviceCodeDict = {}\n",
    "# i = 0\n",
    "# for device in sortedDevices.index:\n",
    "#     deviceCodeDict[device] = i\n",
    "#     i += 1\n",
    "    \n",
    "# sortedDevicesCategory = train_data.groupby('device.deviceCategory')['totals.transactionRevenue'].mean()\n",
    "# sortedDevicesCategory = sortedDevicesCategory.sort_values(ascending=False)\n",
    "# deviceCategoryCodeDict = {}\n",
    "# i = 0\n",
    "# for deviceCategory in sortedDevicesCategory.index:\n",
    "#     deviceCategoryCodeDict[deviceCategory] = i\n",
    "#     i += 1\n",
    "    \n",
    "# sortedBrowser = train_data.groupby('device.browser')['totals.transactionRevenue'].mean()\n",
    "# sortedBrowser = sortedBrowser.sort_values(ascending=False)\n",
    "# browserCodeDict = {}\n",
    "# i = 0\n",
    "# for browser in sortedBrowser.index:\n",
    "#     browserCodeDict[browser] = i\n",
    "#     i += 1\n",
    "\n",
    "# sortedChannelGrouping = train_data.groupby('channelGrouping')['totals.transactionRevenue'].mean()\n",
    "# sortedChannelGrouping = sortedChannelGrouping.sort_values(ascending=False)\n",
    "# channelGroupingCodeDict = {}\n",
    "# i = 0\n",
    "# for device in sortedChannelGrouping.index:\n",
    "#     channelGroupingCodeDict[device] = i\n",
    "#     i += 1\n",
    "\n",
    "# print(channelGroupingCodeDict)\n",
    "# print(deviceCodeDict)\n",
    "# print(browserCodeDict)\n",
    "# print(continentCodeDict)\n",
    "# # print(SubcontinentCodeDict)\n",
    "# print(deviceCategoryCodeDict)\n",
    "# #print(cityCodeDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y%m%d', errors='ignore')\n",
    "    df['year'] = df['date'].apply(lambda x: x.year)\n",
    "    df['month'] = df['date'].apply(lambda x: x.month)\n",
    "    df['day'] = df['date'].apply(lambda x: x.day)\n",
    "    df['weekday'] = df['date'].apply(lambda x: x.weekday())\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_data['totals.transactionRevenue'] = train_data['totals.transactionRevenue'].fillna(0)\n",
    "train_data['totals.pageviews'] = train_data['totals.pageviews'].fillna(1)\n",
    "\n",
    "trainData = train_data.sample(frac=0.8,random_state=200)\n",
    "testData = train_data.drop(trainData.index)\n",
    "test = testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # trainData['geoNetwork.subContinent'] = trainData['geoNetwork.subContinent'].transform(lambda x: SubcontinentCodeDict[x])\n",
    "trainData['geoNetwork.continent'] = trainData['geoNetwork.continent'].transform(lambda x: continentCodeDict[x])\n",
    "trainData['geoNetwork.country'] = trainData['geoNetwork.country'].transform(lambda x: countryCodeDict[x])\n",
    "# # trainData['geoNetwork.city'] = trainData['geoNetwork.city'].transform(lambda x: cityCodeDict[x])\n",
    "# trainData['device.operatingSystem'] = trainData['device.operatingSystem'].transform(lambda x: deviceCodeDict[x])\n",
    "# trainData['device.browser'] = trainData['device.browser'].transform(lambda x: browserCodeDict[x])\n",
    "# # trainData['device.deviceCategory'] = trainData['device.deviceCategory'].transform(lambda x: deviceCategoryCodeDict[x])\n",
    "# trainData['channelGrouping'] = trainData['channelGrouping'].transform(lambda x: channelGroupingCodeDict[x])\n",
    "\n",
    "# #Test\n",
    "# # testData['geoNetwork.subContinent'] = testData['geoNetwork.subContinent'].transform(lambda x: SubcontinentCodeDict[x])\n",
    "test['geoNetwork.continent'] = test['geoNetwork.continent'].transform(lambda x: continentCodeDict[x])\n",
    "test['geoNetwork.country'] = test['geoNetwork.country'].transform(lambda x: countryCodeDict[x])\n",
    "# # testData['geoNetwork.city'] = testData['geoNetwork.city'].transform(lambda x: cityCodeDict[x])\n",
    "# testData['device.operatingSystem'] = testData['device.operatingSystem'].transform(lambda x: deviceCodeDict[x])\n",
    "# testData['device.browser'] = testData['device.browser'].transform(lambda x: browserCodeDict[x])\n",
    "# # testData['device.deviceCategory'] = testData['device.deviceCategory'].transform(lambda x: deviceCategoryCodeDict[x])\n",
    "# testData['channelGrouping'] = testData['channelGrouping'].transform(lambda x: channelGroupingCodeDict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = add_time_features(trainData)\n",
    "# test = add_time_features(testData)\n",
    "# Convert target feature to 'float' type.\n",
    "trainData[\"totals.transactionRevenue\"] = trainData[\"totals.transactionRevenue\"].astype('float')\n",
    "trainData['totals.hits'] = trainData['totals.hits'].astype(float)\n",
    "test['totals.hits'] = test['totals.hits'].astype(float)\n",
    "trainData['totals.pageviews'] = trainData['totals.pageviews'].astype(float)\n",
    "test['totals.pageviews'] = test['totals.pageviews'].astype(float)\n",
    "train = trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['hits.ratio'] = train['totals.hits']/train['totals.pageviews']\n",
    "gp_fullVisitorId_train = train.groupby(['fullVisitorId']).agg('sum')\n",
    "gp_fullVisitorId_train['fullVisitorId'] = gp_fullVisitorId_train.index\n",
    "gp_fullVisitorId_train['mean_hits_per_day'] = gp_fullVisitorId_train.groupby(['day'])['totals.hits'].transform('mean')\n",
    "gp_fullVisitorId_train['mean_pageviews_per_day'] = gp_fullVisitorId_train.groupby(['day'])['totals.pageviews'].transform('mean')\n",
    "gp_fullVisitorId_train['sum_hits_per_day'] = gp_fullVisitorId_train.groupby(['day'])['totals.hits'].transform('sum')\n",
    "gp_fullVisitorId_train['sum_pageviews_per_day'] = gp_fullVisitorId_train.groupby(['day'])['totals.pageviews'].transform('sum')\n",
    "gp_fullVisitorId_train = gp_fullVisitorId_train[['fullVisitorId', 'mean_hits_per_day', 'mean_pageviews_per_day', 'sum_hits_per_day', 'sum_pageviews_per_day']]\n",
    "train = train.join(gp_fullVisitorId_train, on='fullVisitorId', how='inner', rsuffix='_')\n",
    "train.drop(['fullVisitorId_'], axis=1, inplace=True)\n",
    "\n",
    "# Test\n",
    "# test['hits.ratio'] = test['totals.hits']/test['totals.pageviews']\n",
    "gp_fullVisitorId_test = test.groupby(['fullVisitorId']).agg('sum')\n",
    "gp_fullVisitorId_test['fullVisitorId'] = gp_fullVisitorId_test.index\n",
    "gp_fullVisitorId_test['mean_hits_per_day'] = gp_fullVisitorId_test.groupby(['day'])['totals.hits'].transform('mean')\n",
    "gp_fullVisitorId_test['mean_pageviews_per_day'] = gp_fullVisitorId_test.groupby(['day'])['totals.pageviews'].transform('mean')\n",
    "gp_fullVisitorId_test['sum_hits_per_day'] = gp_fullVisitorId_test.groupby(['day'])['totals.hits'].transform('sum')\n",
    "gp_fullVisitorId_test['sum_pageviews_per_day'] = gp_fullVisitorId_test.groupby(['day'])['totals.pageviews'].transform('sum')\n",
    "gp_fullVisitorId_test = gp_fullVisitorId_test[['fullVisitorId', 'mean_hits_per_day', 'mean_pageviews_per_day', 'sum_hits_per_day', 'sum_pageviews_per_day']]\n",
    "test = test.join(gp_fullVisitorId_test, on='fullVisitorId', how='inner', rsuffix='_')\n",
    "test.drop(['fullVisitorId_'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_agg = train.groupby('date')['totals.transactionRevenue'].agg(['count', 'sum'])\n",
    "year_agg = train.groupby('year')['totals.transactionRevenue'].agg(['sum'])\n",
    "month_agg = train.groupby('month')['totals.transactionRevenue'].agg(['sum'])\n",
    "day_agg = train.groupby('day')['totals.transactionRevenue'].agg(['sum'])\n",
    "weekday_agg = train.groupby('weekday')['totals.transactionRevenue'].agg(['count','sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET\n",
      "Rows: 722922\n",
      "Columns: 6\n",
      "Features: ['visitNumber' 'geoNetwork.continent' 'geoNetwork.country' 'totals.hits'\n",
      " 'totals.pageviews' 'totals.transactionRevenue']\n",
      "\n",
      "TEST SET\n",
      "Rows: 180731\n",
      "Columns: 6\n",
      "Features: ['visitNumber' 'geoNetwork.continent' 'geoNetwork.country' 'totals.hits'\n",
      " 'totals.pageviews' 'totals.transactionRevenue']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>geoNetwork.continent</th>\n",
       "      <th>geoNetwork.country</th>\n",
       "      <th>totals.hits</th>\n",
       "      <th>totals.pageviews</th>\n",
       "      <th>totals.transactionRevenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>548725</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697375</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474524</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399762</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903103</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        visitNumber  geoNetwork.continent  geoNetwork.country  totals.hits  \\\n",
       "548725            1                     2                  14         10.0   \n",
       "697375            2                     2                  14          1.0   \n",
       "474524            1                     2                  14          4.0   \n",
       "399762            1                     5                  20          1.0   \n",
       "903103            2                     2                  14         15.0   \n",
       "\n",
       "        totals.pageviews  totals.transactionRevenue  \n",
       "548725              10.0                        0.0  \n",
       "697375               1.0                        0.0  \n",
       "474524               4.0                        0.0  \n",
       "399762               1.0                        0.0  \n",
       "903103              12.0                        0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('TRAIN SET')\n",
    "print('Rows: %s' % train.shape[0])\n",
    "print('Columns: %s' % train.shape[1])\n",
    "print('Features: %s' % train.columns.values)\n",
    "print()\n",
    "print('TEST SET')\n",
    "print('Rows: %s' % test.shape[0])\n",
    "print('Columns: %s' % test.shape[1])\n",
    "print('Features: %s' % test.columns.values)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_features = ['device.isMobile'] #, 'month', 'weekday']\n",
    "# train = pd.get_dummies(train, columns=categorical_features)\n",
    "# test = pd.get_dummies(test, columns=categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # align both data sets (by outer join), to make they have the same amount of features,\n",
    "# # this is required because of the mismatched categorical values in train and test sets\n",
    "# train, test = train.align(test, join='outer', axis=1)\n",
    "\n",
    "# # replace the nan values added by align for 0\n",
    "# train.replace(to_replace=np.nan, value=0, inplace=True)\n",
    "# test.replace(to_replace=np.nan, value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "\n",
    "# X_train = train[train['date']<=datetime.date(2017, 5, 31)]\n",
    "# X_val = train[train['date']>datetime.date(2017, 5, 31)]\n",
    "# test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "Y_train = train['totals.transactionRevenue'].values\n",
    "# Y_val = X_val['totals.transactionRevenue'].values\n",
    "X_train = train.drop(['totals.transactionRevenue'], axis=1)\n",
    "# X_val = X_val.drop(['totals.transactionRevenue'], axis=1)\n",
    "Y_test = test['totals.transactionRevenue'].values\n",
    "X_test = test.drop(['totals.transactionRevenue'], axis=1)\n",
    "# Log transform the labels\n",
    "Y_train = np.log1p(Y_train)\n",
    "# Y_val = np.log1p(Y_val)\n",
    "Y_test = np.log1p(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['visitNumber', 'geoNetwork.continent', 'geoNetwork.country',\n",
       "       'totals.hits', 'totals.pageviews'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_features = ['date', 'fullVisitorId', 'day']#, 'year', 'month', 'day','weekday', 'totals.hits'] #, 'geoNetwork.region', \n",
    "                    #'trafficSource.medium']\n",
    "X_train = X_train.drop(reduce_features, axis=1)\n",
    "# X_val = X_val.drop(reduce_features, axis=1)\n",
    "X_test = X_test.drop(reduce_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size=16):\n",
    "    '''\n",
    "    Return a random image from X, y\n",
    "    '''\n",
    "    \n",
    "    while True:\n",
    "        # choose batch_size random images / labels from the data\n",
    "        idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "        im = X[idx]\n",
    "        label = y[idx]\n",
    "        \n",
    "        specgram = get_specgrams(im)\n",
    "\n",
    "\n",
    "        yield np.concatenate([specgram]), label\n",
    "        \n",
    "batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_features = [ 'channelGrouping',\n",
    "#        'device.operatingSystem', 'device.browser', 'geoNetwork.continent',\n",
    "#        'geoNetwork.country', 'year',\n",
    "#        'month', 'weekday', 'mean_hits_per_day',\n",
    "#        'mean_pageviews_per_day', 'sum_hits_per_day',\n",
    "#        'sum_pageviews_per_day']\n",
    "\n",
    "# # Normalize using Min-Max scaling\n",
    "# scaler = StandardScaler()\n",
    "# X_train[normalized_features] = scaler.fit_transform(X_train[normalized_features])\n",
    "# # X_val[normalized_features] = scaler.transform(X_val[normalized_features])\n",
    "# test[normalized_features] = scaler.transform(test[normalized_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(256, kernel_initializer='glorot_normal', activation='relu'))\n",
    "model.add(Dense(128, kernel_initializer='glorot_normal', activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 50,689\n",
      "Trainable params: 50,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.adam(lr=LEARNING_RATE)\n",
    "model.compile(loss='mse', optimizer=adam)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 722922 samples, validate on 180731 samples\n",
      "Epoch 1/100\n",
      "    44/180731 [..............................] - ETA: 265:46:41 - loss: 37259011.2764"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e11d2f6bcfeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(x=X_train.values, y=Y_train, batch_size=None, epochs=EPOCHS, steps_per_epoch = ceil(X_train.shape[0]/BATCH_SIZE),\n\u001b[0;32m----> 2\u001b[0;31m                     validation_steps = ceil(X_test.shape[0]/BATCH_SIZE), verbose=1, validation_data=(X_test.values, Y_test))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/TensorflowVirtualEnv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/TensorflowVirtualEnv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorflowVirtualEnv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorflowVirtualEnv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorflowVirtualEnv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=X_train.values, y=Y_train, batch_size=None, epochs=EPOCHS, steps_per_epoch = ceil(X_train.shape[0]/BATCH_SIZE),\n",
    "                    validation_steps = ceil(X_test.shape[0]/BATCH_SIZE), verbose=1, validation_data=(X_test.values, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(predictions, Y_test)\n",
    "rmse = np.sqrt(mean_squared_error(predictions, Y_test))\n",
    "\n",
    "print('Model metrics')\n",
    "print('MSE: %.2f' % mse)\n",
    "print('RMSE: %.2f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "y_pred=reg.predict(X_test , num_iteration=reg.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Y_test\n",
    "\n",
    "# y_pred = y_pred + 1\n",
    "# y = y + 1\n",
    "\n",
    "# # for i in range(len(y)):\n",
    "# #     print(y[i], y_pred[i])\n",
    "\n",
    "# y_pred_ln = np.log(y_pred)\n",
    "# y_true_ln = np.log(y)\n",
    "\n",
    "difference = np.subtract(y_pred, y)\n",
    "\n",
    "sqr = np.square(difference)\n",
    "\n",
    "sumSqr = sqr.sum()\n",
    "\n",
    "sumSqrMean = sumSqr/len(y)\n",
    "\n",
    "sumSqrRootMean = np.sqrt(sumSqrMean)\n",
    "sumSqrRootMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (X_test['totals.tr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.read_csv('test_flat.csv', dtype={'fullVisitorId': 'str', 'visitId': 'str'}) # Important!!\n",
    "\n",
    "# test_data['pageviews'] = test_data['pageviews'].fillna(1)\n",
    "\n",
    "# X = test_data[['channelGrouping', 'date', 'visitNumber', \n",
    "#                       'deviceCategory', 'isMobile', 'operatingSystem', 'browser',\n",
    "#                       'city', 'continent', 'country', 'region', \n",
    "#                       'subContinent',\n",
    "#                       'hits', 'pageviews',\n",
    "#                       'medium', 'fullVisitorId']]\n",
    "\n",
    "# X['subContinent'] = X['subContinent'].transform(lambda x: SubcontinentCodeDict[x])\n",
    "# X['continent'] = X['continent'].transform(lambda x: continentCodeDict[x])\n",
    "# X['country'] = X['country'].transform(lambda x: countryCodeDict.get(x,220))\n",
    "# X['city'] = X['city'].transform(lambda x: cityCodeDict.get(x, (len(test_data['city']) -2)))\n",
    "# X['operatingSystem'] = X['operatingSystem'].transform(lambda x: deviceCodeDict.get(x,20))\n",
    "# X['browser'] = X['browser'].transform(lambda x: browserCodeDict.get(x, (len(test_data['browser'])-2)))\n",
    "# X['deviceCategory'] = X['deviceCategory'].transform(lambda x: deviceCategoryCodeDict[x])\n",
    "# X['channelGrouping'] = X['channelGrouping'].transform(lambda x: channelGroupingCodeDict[x])\n",
    "# test = add_time_features(X)\n",
    "\n",
    "# gp_fullVisitorId_test = test.groupby(['fullVisitorId']).agg('sum')\n",
    "# gp_fullVisitorId_test['fullVisitorId'] = gp_fullVisitorId_test.index\n",
    "# gp_fullVisitorId_test['mean_hits_per_day'] = gp_fullVisitorId_test.groupby(['day'])['hits'].transform('mean')\n",
    "# gp_fullVisitorId_test['mean_pageviews_per_day'] = gp_fullVisitorId_test.groupby(['day'])['pageviews'].transform('mean')\n",
    "# gp_fullVisitorId_test['sum_hits_per_day'] = gp_fullVisitorId_test.groupby(['day'])['hits'].transform('sum')\n",
    "# gp_fullVisitorId_test['sum_pageviews_per_day'] = gp_fullVisitorId_test.groupby(['day'])['pageviews'].transform('sum')\n",
    "# gp_fullVisitorId_test = gp_fullVisitorId_test[['fullVisitorId', 'mean_hits_per_day', 'mean_pageviews_per_day', 'sum_hits_per_day', 'sum_pageviews_per_day']]\n",
    "# test = test.join(gp_fullVisitorId_test, on='fullVisitorId', how='inner', rsuffix='_')\n",
    "# test.drop(['fullVisitorId_'], axis=1, inplace=True)\n",
    "\n",
    "# categorical_features = ['isMobile'] #, 'month', 'weekday']\n",
    "# test = pd.get_dummies(test, columns=categorical_features)\n",
    "\n",
    "# reduce_features = ['year', 'month', 'day','weekday', 'date', 'fullVisitorId', 'region', \n",
    "#                     'medium']\n",
    "# test = test.drop(reduce_features, axis=1)\n",
    "\n",
    "# y_pred = reg.predict(test, num_iteration=reg.best_iteration_)\n",
    "\n",
    "# y_pred += 1\n",
    "\n",
    "# test_data['predicted'] = y_pred\n",
    "# # test_data[['fullVisitorId', 'predicted']].to_csv('output_row.csv')\n",
    "\n",
    "# y_pred_sum = test_data.groupby('fullVisitorId')['predicted'].sum()\n",
    "\n",
    "# y_pred_log = np.log(y_pred_sum)\n",
    "        \n",
    "# #y_pred_log.to_csv('output_log.csv')\n",
    "\n",
    "# print(y_pred_log)\n",
    "\n",
    "# # y_pred_sum.to_csv('output_sum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'fullVisitorId':y_pred_log.index, 'PredictedLogRevenue':y_pred_log.values})\n",
    "# submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tintash/anaconda3/envs/TensorflowVirtualEnv/lib/python3.6/site-packages/keras/engine/network.py:180: UserWarning: Model inputs must come from `keras.layers.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to your model was not an Input tensor, it was generated by layer dense_5.\n",
      "Note that input tensors are instantiated via `tensor = keras.layers.Input(shape)`.\n",
      "The tensor that caused the issue was: dense_5/Relu:0\n",
      "  str(x.name))\n",
      "/home/tintash/anaconda3/envs/TensorflowVirtualEnv/lib/python3.6/site-packages/keras/engine/network.py:180: UserWarning: Model inputs must come from `keras.layers.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to your model was not an Input tensor, it was generated by layer dense_6.\n",
      "Note that input tensors are instantiated via `tensor = keras.layers.Input(shape)`.\n",
      "The tensor that caused the issue was: dense_6/Relu:0\n",
      "  str(x.name))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Input layers to a `Model` must be `InputLayer` objects. Received inputs: [<tf.Tensor 'input_5:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'dense_5/Relu:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'dense_6/Relu:0' shape=(?, 128) dtype=float32>]. Input 1 (0-based) originates from layer type `Dense`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-048a54915d89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mo1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/TensorflowVirtualEnv/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorflowVirtualEnv/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorflowVirtualEnv/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    281\u001b[0m                     'from layer type `{}`.'.format(inputs,\n\u001b[1;32m    282\u001b[0m                                                    \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                                                    layer.__class__.__name__))\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_placeholder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input layers to a `Model` must be `InputLayer` objects. Received inputs: [<tf.Tensor 'input_5:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'dense_5/Relu:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'dense_6/Relu:0' shape=(?, 128) dtype=float32>]. Input 1 (0-based) originates from layer type `Dense`."
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "a1 = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "b1 = (Dense(256, kernel_initializer='glorot_normal', activation='relu'))(a1)\n",
    "a2 = (Dense(128, kernel_initializer='glorot_normal', activation='relu')) (b1)\n",
    "o1 = (Dense(1)) (a2)\n",
    "\n",
    "model = Model(inputs=[a1, b1, a2], outputs=[o1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
